{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngpu:  1\n"
     ]
    }
   ],
   "source": [
    "from rnntransducer.model.transducer import Transducer\n",
    "from train.scheduler import TransformerScheduler\n",
    "from train.trainer import Trainer\n",
    "from streaming.winstreamingmodel import StreamingModel\n",
    "from rnntransducer.data.dataloader import FeatureLoader\n",
    "from rnntransducer.train.utils import map_to_cuda\n",
    "import editdistance\n",
    "import torch\n",
    "import time\n",
    "\n",
    "class Solver():\n",
    "    def __init__(self, model, train_wav_path, train_text_path, test_wav_path, \n",
    "                 test_text_path, vab_path, fbank = 40, batch_size=16, ngpu=1, \n",
    "                 train_epochs = 60, accum_steps=4,\n",
    "                 lm=None, lm_weight=0.0):\n",
    "        \n",
    "        self.model = model\n",
    "        self.ngpu = ngpu\n",
    "        self.train_epochs = train_epochs\n",
    "        self.accum_steps = accum_steps\n",
    "\n",
    "        if ngpu >= 1:\n",
    "            model.cuda()\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                                     lr = 0.001, betas=[0.9,0.98], eps= 1.0e-9, \n",
    "                                     weight_decay=1.0e-6, amsgrad= False )\n",
    "\n",
    "        self.scheduler = TransformerScheduler(self.optimizer, 256, 12000, 1.0)\n",
    "\n",
    "        self.train_loader = FeatureLoader(train_wav_path, train_text_path, vab_path, fbank, spec_augment=True, ngpu=1, batch_size=batch_size)\n",
    "        self.test_loader = FeatureLoader(test_wav_path, test_text_path, vab_path, fbank, spec_augment=False, ngpu=1, batch_size=1)\n",
    "\n",
    "        self.lm = lm\n",
    "        self.lm_weight = lm_weight\n",
    "\n",
    "    def train(self):\n",
    "        self.trainer = Trainer(self.model, self.optimizer, self.scheduler, epochs=self.train_epochs,accum_steps=self.accum_steps)\n",
    "        self.trainer.train(self.train_loader)\n",
    "\n",
    "    def load_model(self, path):\n",
    "        chkpt = torch.load(path)\n",
    "        self.model.load_model(chkpt)\n",
    "\n",
    "    def recognize(self):\n",
    "        idx2unit = self.train_loader.dataset.idx2unit()\n",
    "        self.model.eval()\n",
    "        top_n_false_tokens = 0\n",
    "        false_tokens = 0\n",
    "        total_tokens = 0\n",
    "        accu_time = 0\n",
    "\n",
    "        writer = open(\"./log/predict.txt\", 'w', encoding='utf-8')\n",
    "        detail_writer = open(\"./log/predict.log\", 'w', encoding='utf-8')\n",
    "\n",
    "        for step, (utt_id, inputs, targets) in enumerate(self.test_loader.loader):\n",
    "            if self.ngpu>0:\n",
    "                inputs = map_to_cuda(inputs)\n",
    "\n",
    "            st = time.time()\n",
    "            preds = self.model.recognize(inputs)\n",
    "            et = time.time()\n",
    "            span = et - st\n",
    "            accu_time += span\n",
    "\n",
    "            totals = len(self.test_loader.loader)\n",
    "\n",
    "            truths = targets['targets']\n",
    "            truths_length = targets['targets_length']\n",
    "\n",
    "            for b in range(len(preds)):\n",
    "                n = step + b\n",
    "\n",
    "                truth = [idx2unit[i.item()] for i in truths[b][:truths_length[b]]]\n",
    "                truth = ' '.join(truth)\n",
    "\n",
    "                print_info = '[%d / %d ] %s - truth: %s' % (n, totals, utt_id[b], truth)\n",
    "                detail_writer.write(print_info+'\\n')\n",
    "                total_tokens += len(truth.split())  \n",
    "\n",
    "                nbest_min_false_tokens = 1e10\n",
    "                pred = preds[b]\n",
    "\n",
    "                _truth = truth.replace(\"<PESN> \", \"\").replace(\"<VIET> \", \"\").replace(\"<SWAH> \", \"\")\n",
    "                _pred = pred.replace(\"<PESN> \", \"\").replace(\"<VIET> \", \"\").replace(\"<SWAH> \", \"\")\n",
    "                n_diff = editdistance.eval(_truth.split(), _pred.split())\n",
    "\n",
    "                false_tokens += n_diff\n",
    "                nbest_min_false_tokens = min(nbest_min_false_tokens, n_diff)\n",
    "\n",
    "                print_info = '[%d / %d ] %s - pred : %s' % (n, totals, utt_id[b], pred)\n",
    "                detail_writer.write(print_info+'\\n')\n",
    "                \n",
    "                writer.write(utt_id[b] + ' ' + preds[b] + '\\n')\n",
    "                top_n_false_tokens += nbest_min_false_tokens\n",
    "\n",
    "                detail_writer.write('\\n')\n",
    "\n",
    "        writer.close()\n",
    "        detail_writer.close()\n",
    "\n",
    "        with open(\"./log/result.txt\", 'w', encoding='utf-8') as w:\n",
    "            cer = false_tokens / total_tokens * 100\n",
    "            w.write('The CER is %.3f. \\n' % cer)\n",
    "\n",
    "fbank=80\n",
    "enc_hidden=512\n",
    "enc_out=340\n",
    "enc_layers=6 \n",
    "dec_hidden=512\n",
    "vocab_size=4232\n",
    "dec_out=320\n",
    "dec_layers=1\n",
    "joint_dim=512\n",
    "dropout = 0.2\n",
    "\n",
    "train_wav_path = \"egs/aishell/data/train/wav.scp\"\n",
    "train_text_path = \"egs/aishell/data/train/text\"\n",
    "test_wav_path = \"egs/aishell/data/test/wav.scp\"\n",
    "test_text_path = \"egs/aishell/data/test/text\"\n",
    "vab_path = \"egs/aishell/data/transducer_vab\"\n",
    "batch_size = 16\n",
    "train_epochs = 80\n",
    "accum_steps = 4\n",
    "\n",
    "ngpu = 1 if torch.cuda.is_available() else 0\n",
    "print(\"ngpu: \", ngpu)\n",
    "\n",
    "model = Transducer(fbank, enc_hidden, enc_out, enc_layers, dec_hidden, vocab_size, dec_out, dec_layers, joint_dim, dropout)\n",
    "\n",
    "solver = Solver(model, train_wav_path,train_text_path, test_wav_path, test_text_path,\n",
    "                vab_path, fbank, batch_size, ngpu, train_epochs = train_epochs, accum_steps=accum_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Training-Epoch-0(0.42627%), Global Step:10, lr:0.00000048, Loss:980.17732, AvgLoss: 1048.47820, Run Time:3.759\n",
      "-Training-Epoch-0(0.95910%), Global Step:20, lr:0.00000095, Loss:1141.84833, AvgLoss: 1055.42610, Run Time:4.798\n",
      "-Training-Epoch-0(1.49194%), Global Step:30, lr:0.00000143, Loss:1020.76202, AvgLoss: 1053.83716, Run Time:4.702\n",
      "-Training-Epoch-0(2.02478%), Global Step:40, lr:0.00000190, Loss:1129.08527, AvgLoss: 1056.80785, Run Time:4.545\n",
      "-Training-Epoch-0(2.55761%), Global Step:50, lr:0.00000238, Loss:1048.45566, AvgLoss: 1056.47819, Run Time:4.343\n",
      "-Training-Epoch-0(3.09045%), Global Step:60, lr:0.00000285, Loss:1040.27881, AvgLoss: 1058.44967, Run Time:4.581\n",
      "-Training-Epoch-0(3.62328%), Global Step:70, lr:0.00000333, Loss:1071.36996, AvgLoss: 1057.58686, Run Time:4.856\n",
      "-Training-Epoch-0(4.15612%), Global Step:80, lr:0.00000380, Loss:1089.80469, AvgLoss: 1058.64548, Run Time:4.703\n",
      "-Training-Epoch-0(4.68896%), Global Step:90, lr:0.00000428, Loss:1046.68951, AvgLoss: 1060.18512, Run Time:5.014\n",
      "-Training-Epoch-0(5.22179%), Global Step:100, lr:0.00000475, Loss:1050.23376, AvgLoss: 1059.77818, Run Time:4.663\n",
      "-Training-Epoch-0(5.75463%), Global Step:110, lr:0.00000523, Loss:1013.58047, AvgLoss: 1058.79740, Run Time:4.438\n",
      "-Training-Epoch-0(6.28747%), Global Step:120, lr:0.00000571, Loss:1083.83456, AvgLoss: 1059.36412, Run Time:4.787\n",
      "-Training-Epoch-0(6.82030%), Global Step:130, lr:0.00000618, Loss:1048.58922, AvgLoss: 1060.28284, Run Time:4.684\n",
      "-Training-Epoch-0(7.35314%), Global Step:140, lr:0.00000666, Loss:993.82443, AvgLoss: 1057.48404, Run Time:4.629\n",
      "-Training-Epoch-0(7.88597%), Global Step:150, lr:0.00000713, Loss:1054.09030, AvgLoss: 1055.23722, Run Time:4.629\n",
      "-Training-Epoch-0(8.41881%), Global Step:160, lr:0.00000761, Loss:1037.12088, AvgLoss: 1052.28398, Run Time:4.799\n",
      "-Training-Epoch-0(8.95165%), Global Step:170, lr:0.00000808, Loss:1033.30295, AvgLoss: 1052.73662, Run Time:5.072\n",
      "-Training-Epoch-0(9.48448%), Global Step:180, lr:0.00000856, Loss:1011.95407, AvgLoss: 1050.95803, Run Time:4.600\n",
      "-Training-Epoch-0(10.01732%), Global Step:190, lr:0.00000903, Loss:1070.21124, AvgLoss: 1048.35018, Run Time:4.620\n",
      "-Training-Epoch-0(10.55015%), Global Step:200, lr:0.00000951, Loss:1040.19244, AvgLoss: 1047.29815, Run Time:4.868\n",
      "-Training-Epoch-0(11.08299%), Global Step:210, lr:0.00000998, Loss:970.84286, AvgLoss: 1043.80607, Run Time:4.460\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m solver\u001b[38;5;241m.\u001b[39mrecognize()\n",
      "Cell \u001b[0;32mIn[1], line 39\u001b[0m, in \u001b[0;36mSolver.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m Trainer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_epochs,accum_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccum_steps)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/sdb/guoyujie_space/Transformer/train/trainer.py:31\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_loader):\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_epochs):\n\u001b[0;32m---> 31\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mepoch()\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-*Train-Epoch-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m*-, AvgLoss:\u001b[39m\u001b[38;5;132;01m%.5f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_epochs, train_loss))\n",
      "File \u001b[0;32m/mnt/sdb/guoyujie_space/Transformer/train/trainer.py:50\u001b[0m, in \u001b[0;36mTrainer.train_one_epoch\u001b[0;34m(self, epoch, train_loader)\u001b[0m\n\u001b[1;32m     48\u001b[0m step_loss \u001b[38;5;241m=\u001b[39m AverageMeter()\n\u001b[1;32m     49\u001b[0m span \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (_, inputs, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     53\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m map_to_cuda(inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/mnt/sdb/guoyujie_space/Transformer/rnntransducer/data/dataset.py:42\u001b[0m, in \u001b[0;36mAudioDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     39\u001b[0m utt_id, path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_list[index]\n\u001b[1;32m     40\u001b[0m wavform, sample_frequency \u001b[38;5;241m=\u001b[39m ta\u001b[38;5;241m.\u001b[39mload(path)\n\u001b[0;32m---> 42\u001b[0m feature \u001b[38;5;241m=\u001b[39m \u001b[43mta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompliance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkaldi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfbank\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwavform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_mel_bins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfbank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_frequency\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdither\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubsampling(feature)\n\u001b[1;32m     49\u001b[0m feature \u001b[38;5;241m=\u001b[39m normalization(feature)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/torchaudio/compliance/kaldi.py:616\u001b[0m, in \u001b[0;36mfbank\u001b[0;34m(waveform, blackman_coeff, channel, dither, energy_floor, frame_length, frame_shift, high_freq, htk_compat, low_freq, min_duration, num_mel_bins, preemphasis_coefficient, raw_energy, remove_dc_offset, round_to_power_of_two, sample_frequency, snip_edges, subtract_mean, use_energy, use_log_fbank, use_power, vtln_high, vtln_low, vtln_warp, window_type)\u001b[0m\n\u001b[1;32m    600\u001b[0m strided_input, signal_log_energy \u001b[38;5;241m=\u001b[39m _get_window(\n\u001b[1;32m    601\u001b[0m     waveform,\n\u001b[1;32m    602\u001b[0m     padded_window_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    612\u001b[0m     preemphasis_coefficient,\n\u001b[1;32m    613\u001b[0m )\n\u001b[1;32m    615\u001b[0m \u001b[38;5;66;03m# size (m, padded_window_size // 2 + 1)\u001b[39;00m\n\u001b[0;32m--> 616\u001b[0m spectrum \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrfft\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrided_input\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_power:\n\u001b[1;32m    618\u001b[0m     spectrum \u001b[38;5;241m=\u001b[39m spectrum\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2.0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "solver.train()\n",
    "solver.recognize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
